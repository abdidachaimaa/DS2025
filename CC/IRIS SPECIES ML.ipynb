{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyqHH18bslbu",
        "outputId": "28d3ca6a-0c90-4ef2-8b82-dc8aa08932e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'iris' dataset.\n",
            "Path to dataset files: /kaggle/input/iris\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"uciml/iris\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv(f'{path}/Iris.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nettoyage des donn√©es\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Info:\")\n",
        "dataset.info()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(dataset.isnull().sum())\n",
        "\n",
        "# Check for duplicate rows\n",
        "print(\"\\nDuplicate Rows:\")\n",
        "duplicate_rows = dataset.duplicated().sum()\n",
        "print(duplicate_rows)\n",
        "\n",
        "# If no issues are found after inspection, print 'dataset already clean'\n",
        "if dataset.isnull().sum().sum() == 0 and duplicate_rows == 0:\n",
        "    print(\"\\nDataset is already clean.\")\n",
        "else:\n",
        "    # Placeholder for cleaning steps if issues are found\n",
        "    # For the Iris dataset, it's typically very clean, so this part might not execute.\n",
        "    print(\"\\nData cleaning steps might be needed. (Not implemented yet, based on findings above.)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiFOzLTYu1-w",
        "outputId": "6d7c6692-a183-4dd6-f07e-759bcbc9dd60"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             150 non-null    int64  \n",
            " 1   SepalLengthCm  150 non-null    float64\n",
            " 2   SepalWidthCm   150 non-null    float64\n",
            " 3   PetalLengthCm  150 non-null    float64\n",
            " 4   PetalWidthCm   150 non-null    float64\n",
            " 5   Species        150 non-null    object \n",
            "dtypes: float64(4), int64(1), object(1)\n",
            "memory usage: 7.2+ KB\n",
            "\n",
            "Missing Values:\n",
            "Id               0\n",
            "SepalLengthCm    0\n",
            "SepalWidthCm     0\n",
            "PetalLengthCm    0\n",
            "PetalWidthCm     0\n",
            "Species          0\n",
            "dtype: int64\n",
            "\n",
            "Duplicate Rows:\n",
            "0\n",
            "\n",
            "Dataset is already clean.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task\n",
        "Train and evaluate a Random Forest Classifier model on the Iris dataset to predict the 'Species' of Iris flowers, and summarize its performance.\n",
        "\n",
        "## Prepare Data for Random Forest\n",
        "\n",
        "### Subtask:\n",
        "Separate the features (X) from the target variable (y), which is 'Species'. Then, split the data into training and testing sets to prepare for model training.\n",
        "\n",
        "**Reasoning**:\n",
        "To prepare the data for model training, I will first separate the features (X) from the target variable (y) by dropping 'Id' and 'Species' for X and assigning 'Species' to y. Then, I will split the data into training and testing sets using `train_test_split` with the specified parameters to ensure reproducibility and proper evaluation."
      ],
      "metadata": {
        "id": "4eVfcFCevY7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = dataset.drop(['Id', 'Species'], axis=1)\n",
        "y = dataset['Species']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfpztoSrvWQB",
        "outputId": "7d965521-01b4-40ad-b83f-c680020cfd38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (120, 4)\n",
            "Shape of X_test: (30, 4)\n",
            "Shape of y_train: (120,)\n",
            "Shape of y_test: (30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Random Forest Model\n",
        "\n",
        "### Subtask:\n",
        "Train a Random Forest Classifier model using the training data. This model will learn to predict the 'Species' based on the given features.\n",
        "**Reasoning**:\n",
        "To train the Random Forest model, I will import the `RandomForestClassifier` class, instantiate it with a `random_state` for reproducibility, and then fit the model to the training data (`X_train` and `y_train`)."
      ],
      "metadata": {
        "id": "1e75Sdi1vqKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate the RandomForestClassifier model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model using the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Random Forest Classifier model trained successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMOJlY1ovuBm",
        "outputId": "94e3bd93-0c87-4837-8d57-58bd8afe5a5f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Random Forest Model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the trained Random Forest model on the test data. This will include calculating metrics such as accuracy to understand how well the model predicts the Iris species.\n",
        "\n",
        "**Reasoning**:\n",
        "To evaluate the model's performance, I will first make predictions on the test data using the trained model and then import the necessary evaluation metrics from `sklearn.metrics`."
      ],
      "metadata": {
        "id": "TfBroRqFv0U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Predictions on test data generated successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1KbaTD_vz-n",
        "outputId": "b0e87192-efb6-42da-b84f-5953ece2a718"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions on test data generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "Now that predictions have been made and the necessary metrics imported, I will calculate and print the accuracy score, classification report, and confusion matrix to evaluate the model's performance on the test data."
      ],
      "metadata": {
        "id": "yiuu6xbVwAdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOMGi1FowALv",
        "outputId": "6b23f71d-308e-4efd-ef28-22b44f2d3a0b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        10\n",
            "Iris-versicolor       1.00      1.00      1.00         9\n",
            " Iris-virginica       1.00      1.00      1.00        11\n",
            "\n",
            "       accuracy                           1.00        30\n",
            "      macro avg       1.00      1.00      1.00        30\n",
            "   weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    }
  ]
}